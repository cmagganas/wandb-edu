{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/llm-apps-course/notebooks/01.%20Using_APIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{llmapps-intro} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LLM APIs\n",
    "\n",
    "We will explore OpenAI models API to generate text.\n",
    "\n",
    "<!--- @wandbcode{llmapps-intro} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai tiktoken wandb -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "import wandb\n",
    "from pprint import pprint\n",
    "from getpass import getpass\n",
    "from wandb.integration.openai import autolog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need an OpenAI API key to run this notebook. You can get one [here](https://platform.openai.com/account/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter password in the VS Code prompt at the top of your VS Code window!\n",
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "  print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's enable W&B autologging to track our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcmagganas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cmagganas/wandb-edu/edu/llm-apps-course/notebooks/wandb/run-20230626_210615-vas61969</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cmagganas/llmapps/runs/vas61969' target=\"_blank\">smart-shadow-3</a></strong> to <a href='https://wandb.ai/cmagganas/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cmagganas/llmapps' target=\"_blank\">https://wandb.ai/cmagganas/llmapps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cmagganas/llmapps/runs/vas61969' target=\"_blank\">https://wandb.ai/cmagganas/llmapps/runs/vas61969</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start logging to W&B\n",
    "autolog({\"project\":\"llmapps\", \"entity\":\"cmagganas\", \"job_type\": \"introduction\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1135, 2337, 1222, 8436, 1386, 318, 7427, 0]\n",
      "Weights & Biases is awesome!\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "enc = encoding.encode(\"Weights & Biases is awesome!\")\n",
    "print(enc)\n",
    "print(encoding.decode(enc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can decode the tokens one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135\tWe\n",
      "2337\tights\n",
      "1222\t &\n",
      "8436\t Bi\n",
      "1386\tases\n",
      "318\t is\n",
      "7427\t awesome\n",
      "0\t!\n"
     ]
    }
   ],
   "source": [
    "for token_id in enc:\n",
    "    print(f\"{token_id}\\t{encoding.decode([token_id])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note how the leading tokens contain spacing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample some text from the model. For this, let's create a wrapper function around the temperature parameters.\n",
    "Higher temperature will result in more random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_temperature(temp):\n",
    "  \"Generate text with a given temperature, higher temperature means more randomness\"\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Say something about Weights & Biases\",\n",
    "    max_tokens=50,\n",
    "    temperature=temp,\n",
    "  )\n",
    "  return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP: 0, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an amazing tool for tracking and visualizing machine '\n",
      " 'learning experiments. It helps to keep track of all the different '\n",
      " 'experiments you run, and provides powerful visualizations to help you '\n",
      " \"understand the results. It's a great way\")\n",
      "('TEMP: 0.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an amazing tool for tracking and managing machine '\n",
      " 'learning experiments. It allows you to easily visualize, compare, and share '\n",
      " 'the results of your experiments, helping you to identify trends and improve '\n",
      " 'your models. With its powerful search')\n",
      "('TEMP: 1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an AI experiment tracking platform that enables data '\n",
      " 'scientists and ML engineers to track and visualize the performance of their '\n",
      " \"machine learning models. It's a great tool for tracking, analyzing, and \"\n",
      " 'comparing ML experiments, and for creating')\n",
      "('TEMP: 1.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a powerful tool that helps data scientists and ML '\n",
      " 'engineers track and gain visibility into their machine learning models. With '\n",
      " 'automated, real-time, enterprise scalability and cloud support, Weights and '\n",
      " 'Biases helps users quickly')\n",
      "('TEMP: 2, GENERATION: \"\\n'\n",
      " '\\n'\n",
      " 'Weights & Biases makes it easy on Data Scientists leverage simpler projects '\n",
      " 'easier-- Specifically MLOps Reaearch Highlights define ML Methods phases '\n",
      " 'tracking holistically taking performance through sharing reported '\n",
      " 'achievements promoting Collaborative Ideation Developing automation For '\n",
      " 'accelerated.')\n"
     ]
    }
   ],
   "source": [
    "for temp in [0, 0.5, 1, 1.5, 2]:\n",
    "  pprint(f'TEMP: {temp}, GENERATION: {generate_with_temperature(temp)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the [`top_p` parameter](https://platform.openai.com/docs/api-reference/completions/create#completions/create-top_p) to control the diversity of the generated text. This parameter controls the cumulative probability of the next token. For example, if `top_p=0.9`, the model will pick the next token from the top 90% most likely tokens. The higher the `top_p` the more likely the model will pick a token that it hasn't seen before. You should only use one of `temperature` or `top_p` at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_topp(topp):\n",
    "  \"Generate text with a given top-p, higher top-p means more randomness\"\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Say something about Weights & Biases\",\n",
    "    max_tokens=50,\n",
    "    top_p=topp,\n",
    "    )\n",
    "  return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TOP_P: 0.01, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an amazing tool for tracking and analyzing machine '\n",
      " 'learning experiments. It provides powerful visualizations and insights into '\n",
      " 'model performance, enabling data scientists to quickly identify areas of '\n",
      " 'improvement and optimize their models.')\n",
      "('TOP_P: 0.1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an amazing tool for tracking and analyzing machine '\n",
      " 'learning experiments. It provides powerful visualizations and insights into '\n",
      " 'model performance, enabling data scientists to quickly identify areas of '\n",
      " 'improvement and optimize their models.')\n",
      "('TOP_P: 0.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an amazing tool for tracking and analyzing machine '\n",
      " 'learning experiments. It helps to easily compare different models and their '\n",
      " 'performance, and provides useful visualizations and insights to help make '\n",
      " 'data-driven decisions.')\n",
      "('TOP_P: 1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a powerful machine learning platform for training, '\n",
      " 'monitoring, and comparing deep learning models that provides advanced '\n",
      " 'tracking and collaboration tools. It simplifies the experimentation workflow '\n",
      " 'by automatically tracking all the metrics and keeping a detailed history of '\n",
      " 'each')\n"
     ]
    }
   ],
   "source": [
    "for topp in [0.01, 0.1, 0.5, 1]:\n",
    "  pprint(f'TOP_P: {topp}, GENERATION: {generate_with_topp(topp)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's switch to chat mode and see how the model responds to our messages. We have some control over the model's response by passing a `system-role`, here we can steer to model to adhere to a certain behaviour.\n",
    "\n",
    "> We are using `gpt-3.5-turbo`, this model is faster and cheaper than `davinci-003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7VuH8dfXQjHMoLx4fGS9VIMAhgFuH at 0x7fa7787a4b80> JSON: {\n",
       "  \"id\": \"chatcmpl-7VuH8dfXQjHMoLx4fGS9VIMAhgFuH\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1687838846,\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Weights & Biases is a machine learning platform that helps data scientists and machine learning engineers track and visualize their experiments. It provides tools for experiment management, hyperparameter tuning, and model visualization, making it easier to understand and improve machine learning models. Weights & Biases also offers integrations with popular machine learning frameworks like TensorFlow, PyTorch, and Keras.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 27,\n",
       "    \"completion_tokens\": 74,\n",
       "    \"total_tokens\": 101\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Say something about Weights & Biases\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the response is a JSON object with relevant information about the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Weights & Biases is a machine learning platform that helps data scientists '\n",
      " 'and machine learning engineers track and visualize their experiments. It '\n",
      " 'provides tools for experiment management, hyperparameter tuning, and model '\n",
      " 'visualization, making it easier to understand and improve machine learning '\n",
      " 'models. Weights & Biases also offers integrations with popular machine '\n",
      " 'learning frameworks like TensorFlow, PyTorch, and Keras.')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>▂▂▂▂▂▁▁▁▂█</td></tr><tr><td>usage/elapsed_time</td><td>█▆▃▄▆▂▁▅▄▅</td></tr><tr><td>usage/prompt_tokens</td><td>▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>usage/total_tokens</td><td>▂▂▂▂▂▁▁▁▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>74</td></tr><tr><td>usage/elapsed_time</td><td>3.59035</td></tr><tr><td>usage/prompt_tokens</td><td>27</td></tr><tr><td>usage/total_tokens</td><td>101</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-shadow-3</strong> at: <a href='https://wandb.ai/cmagganas/llmapps/runs/vas61969' target=\"_blank\">https://wandb.ai/cmagganas/llmapps/runs/vas61969</a><br/>Synced 6 W&B file(s), 10 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230626_210615-vas61969/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
