{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/edu/blob/main/llm-apps-course/notebooks/02.%20Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{llmapps-generation} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "<!--- @wandbcode{llmapps-generation} -->\n",
    "\n",
    "In this notebook we will dive deeper on prompting the model by passing a better context by using available data from users questions and using the documentation files to generate better answers.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqqq rich openai tiktoken wandb tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import openai\n",
    "import tiktoken\n",
    "from pprint import pprint\n",
    "from rich.markdown import Markdown\n",
    "import pandas as pd\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential, # for exponential backoff\n",
    ")  \n",
    "import wandb\n",
    "from wandb.integration.openai import autolog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need an OpenAI API key to run this notebook. You can get one [here](https://platform.openai.com/account/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's enable W&B autologging to track our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcmagganas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cmagganas/wandb-edu/edu/llm-apps-course/notebooks/wandb/run-20230626_211011-vfjiv4yp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cmagganas/llmapps/runs/vfjiv4yp' target=\"_blank\">devoted-energy-4</a></strong> to <a href='https://wandb.ai/cmagganas/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cmagganas/llmapps' target=\"_blank\">https://wandb.ai/cmagganas/llmapps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cmagganas/llmapps/runs/vfjiv4yp' target=\"_blank\">https://wandb.ai/cmagganas/llmapps/runs/vfjiv4yp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start logging to W&B\n",
    "autolog({\"project\":\"llmapps\", \"entity\":\"cmagganas\", \"job_type\": \"generation\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic support questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add a retry behavior in case we hit the API rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return openai.ChatCompletion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "# MODEL_NAME = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How can I save a trained model in W&amp;B and access it later for inference or further training?                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How can I save a trained model in W&B and access it later for inference or further training?                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"How can I customize my project dashboard on Weights &amp; Biases to better visualize my experiment results?\"          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"How can I customize my project dashboard on Weights & Biases to better visualize my experiment results?\"          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"How can I track multiple experiments and compare their results easily on the W&amp;B platform?\"                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"How can I track multiple experiments and compare their results easily on the W&B platform?\"                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"How can I track and compare model performance between different experiments in W&amp;B?\"                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"How can I track and compare model performance between different experiments in W&B?\"                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\"How can I use Weights and Biases to track and compare the performance of multiple machine learning models over    \n",
       "time?\"                                                                                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\"How can I use Weights and Biases to track and compare the performance of multiple machine learning models over    \n",
       "time?\"                                                                                                             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Generate a support question from a W&B user\"\n",
    "\n",
    "def generate_and_print(system_prompt, user_prompt, n=5):\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    responses = completion_with_backoff(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        n = n,\n",
    "        )\n",
    "    for response in responses.choices:\n",
    "        generation = response.message.content\n",
    "        display(Markdown(generation))\n",
    "    \n",
    "generate_and_print(system_prompt, user_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read some user submitted queries from the file `examples.txt`. This file contains multiline questions separated by tabs (`\\t`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'We have 228 real queries:'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sample one: \"can I use the column subsample parameter config file for xgboost parameters through sweeps?\"          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sample one: \"can I use the column subsample parameter config file for xgboost parameters through sweeps?\"          \n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiter = \"\\t\" # tab separated queries\n",
    "with open(\"examples.txt\", \"r\") as file:\n",
    "    data = file.read()\n",
    "    real_queries = data.split(delimiter)\n",
    "\n",
    "pprint(f\"We have {len(real_queries)} real queries:\")  \n",
    "Markdown(f\"Sample one: \\n\\\"{random.choice(real_queries)}\\\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use those real user questions to guide our model to produce synthetic questions like those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generate a support question from a W&amp;B user Below you will find a few examples of real user queries: weights &amp;     \n",
       "biases have released a new product called wandb-geofinder to improve logging geographical data to wandb. Using     \n",
       "wandb-geofinder, what is the capital of Ireland I was trying to save model checkpoints using wandb.save(path) where\n",
       "my path is ~/.save_folder (notice the dot), I am getting an error. I am running on windows. I Let's start!         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Generate a support question from a W&B user Below you will find a few examples of real user queries: weights &     \n",
       "biases have released a new product called wandb-geofinder to improve logging geographical data to wandb. Using     \n",
       "wandb-geofinder, what is the capital of Ireland I was trying to save model checkpoints using wandb.save(path) where\n",
       "my path is ~/.save_folder (notice the dot), I am getting an error. I am running on windows. I Let's start!         \n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_few_shot_prompt(queries, n=3):\n",
    "    prompt = \"Generate a support question from a W&B user\\n\" +\\\n",
    "        \"Below you will find a few examples of real user queries:\\n\"\n",
    "    for _ in range(n):\n",
    "        prompt += random.choice(queries) + \"\\n\"\n",
    "    prompt += \"Let's start!\"\n",
    "    return prompt\n",
    "\n",
    "generation_prompt = generate_few_shot_prompt(real_queries)\n",
    "Markdown(generation_prompt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI `Chat` models are really good at following instructions with a few examples. Let's see how it does here. This is going to use some context from the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sure, here's a possible support question from a W&amp;B user:                                                          \n",
       "\n",
       "\"I am trying to run a hyperparameter sweep with W&amp;B sweeps feature, but I keep getting an error when trying to run \n",
       "my script on a remote machine. I have set up my API key and configured my sweep YAML file correctly, but I can't   \n",
       "seem to figure out why my script won't run properly. Can you help me troubleshoot this issue?\"                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sure, here's a possible support question from a W&B user:                                                          \n",
       "\n",
       "\"I am trying to run a hyperparameter sweep with W&B sweeps feature, but I keep getting an error when trying to run \n",
       "my script on a remote machine. I have set up my API key and configured my sweep YAML file correctly, but I can't   \n",
       "seem to figure out why my script won't run properly. Can you help me troubleshoot this issue?\"                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sure, here's a support question a W&amp;B user might have:                                                             \n",
       "\n",
       "I'm trying to use wandb.log() to log my model's training metrics, but I keep getting an error that says \"wandb:    \n",
       "ERROR Not authenticated\". How do I authenticate my account in order to use wandb.log()?                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sure, here's a support question a W&B user might have:                                                             \n",
       "\n",
       "I'm trying to use wandb.log() to log my model's training metrics, but I keep getting an error that says \"wandb:    \n",
       "ERROR Not authenticated\". How do I authenticate my account in order to use wandb.log()?                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sure thing! Here's a possible support question from a W&amp;B user:                                                    \n",
       "\n",
       "\"I'm using W&amp;B to log my experiments, and I noticed that some of the plots and graphs are not showing up on my     \n",
       "dashboard, even though the runs seem to be getting logged correctly. What could be causing this issue?\"            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sure thing! Here's a possible support question from a W&B user:                                                    \n",
       "\n",
       "\"I'm using W&B to log my experiments, and I noticed that some of the plots and graphs are not showing up on my     \n",
       "dashboard, even though the runs seem to be getting logged correctly. What could be causing this issue?\"            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here's a support question from a W&amp;B user: I'm using W&amp;B for my deep learning project and I want to track the      \n",
       "performance of my model with different hyperparameters. How can I easily compare the results?                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here's a support question from a W&B user: I'm using W&B for my deep learning project and I want to track the      \n",
       "performance of my model with different hyperparameters. How can I easily compare the results?                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">How do I integrate W&amp;B with my machine learning framework?                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "How do I integrate W&B with my machine learning framework?                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_print(system_prompt, user_prompt=generation_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Context & Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to find all the markdown files in a directory and return it's content and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_md_files(directory):\n",
    "    \"Find all markdown files in a directory and return their content and path\"\n",
    "    md_files = []\n",
    "    for file in Path(directory).rglob(\"*.md\"):\n",
    "        with open(file, 'r', encoding='utf-8') as md_file:\n",
    "            content = md_file.read()\n",
    "        md_files.append((file.relative_to(directory), content))\n",
    "    return md_files\n",
    "\n",
    "documents = find_md_files('../docs_sample/')\n",
    "len(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the documents are not too long for our context window. We need to compute the number of tokens in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2093, 2940, 2529, 1644, 803, 2596, 1206, 365, 537, 4179, 956]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(MODEL_NAME)\n",
    "tokens_per_document = [len(tokenizer.encode(document)) for _, document in documents]\n",
    "pprint(tokens_per_document)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of them are too long - instead of using entire documents, we'll extract a random chunk from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a random chunk from a document\n",
    "def extract_random_chunk(document, max_tokens=512):\n",
    "    tokens = tokenizer.encode(document)\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return document\n",
    "    start = random.randint(0, len(tokens) - max_tokens)\n",
    "    end = start + max_tokens\n",
    "    return tokenizer.decode(tokens[start:end])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use that extracted chunk to create a question that can be answered by the document. This way we can generate questions that our current documentation is capable of answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_prompt(chunk):\n",
    "    prompt = \"Generate a support question from a W&B user\\n\" +\\\n",
    "        \"The question should be answerable by provided fragment of W&B documentation.\\n\" +\\\n",
    "        \"Below you will find a fragment of W&B documentation:\\n\" +\\\n",
    "        chunk + \"\\n\" +\\\n",
    "        \"Let's start!\"\n",
    "    return prompt\n",
    "\n",
    "chunk = extract_random_chunk(documents[0][1])\n",
    "generation_prompt = generate_context_prompt(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Generate a support question from a W&amp;B user The question should be answerable by provided fragment of W&amp;B          \n",
       "documentation. Below you will find a fragment of W&amp;B documentation: the <span style=\"font-weight: bold\">Team</span> dropdown menu, and select a role type \n",
       "from the <span style=\"font-weight: bold\">Organizational Role</span> dropdown menu.                                                                        \n",
       "\n",
       "🌆 <a href=\"@site/static/images/app_ui/ezgif-3-b665ff2fa9.gif\" target=\"_blank\">ezgif-3-b665ff2fa9.gif</a>                                                                                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span>Select the <span style=\"font-weight: bold\">Add</span> button.                                                                                          \n",
       "\n",
       ":::info                                                                                                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>If you have an Enterprise account, please contact your Account Executive to invite new members to your team. :::\n",
       "\n",
       "\n",
       "                                               <span style=\"font-weight: bold; text-decoration: underline\">Create a Team Profile</span>                                               \n",
       "\n",
       "You can customize your team's profile page to show an introduction and showcase reports and projects that are      \n",
       "visible to the public or team members. Present reports, projects, and external links.                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Highlight your best research</span> to visitors by showcasing your best public reports                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Showcase the most active projects</span> to make it easier for teammates to find them                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Find collaborators</span> by adding external links to your company or research lab's website and any papers you've     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>published                                                                                                       \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "                                                <span style=\"font-weight: bold; text-decoration: underline\">Remove team members</span>                                                \n",
       "\n",
       "Team admins can open the team settings page and click the delete button next to the departing member's name. Any   \n",
       "runs that they logged to the team will remain after a user is removed.                                             \n",
       "\n",
       "\n",
       "                                            <span style=\"font-weight: bold; text-decoration: underline\">Team Roles and Permissions</span>                                             \n",
       "\n",
       "Select one a team role when you invite colleagues to join a team. There are four team role options:                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Admin</span>: Team admins can add and remove other admins or team members. They have permissions to modify all projects\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and full deletion permissions. This includes, but is not limited to, deleting runs, projects, artifacts, and    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>sweeps.                                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Member</span>: A regular member of the team. A team member is invited by email by the team admin. A team member cannot \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>invite other members. Team members can only delete runs and sweep runs created by that member. Suppose you have \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>two members A and B. Member B moves a Run from team B's project to a different project owned by Member A. Member\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>A can not delete the Run Member B moved to Member A's project. Only the member that creates the Run, or the team\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>admin, can delete the run.                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Service</span>: A service worker, an API key useful for using W&amp;B with your run automation tools. If you use the API   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>key from a service account for your team, make sure to set the environment variable <span style=\"font-weight: bold\">WANDB_USERNAME</span> to attribute \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>runs to the correct user.                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">View-Only (Enterprise-only feature)</span>: View-Only members can view assets within the team such as runs, reports,   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and workspaces. They can Let's start!                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Generate a support question from a W&B user The question should be answerable by provided fragment of W&B          \n",
       "documentation. Below you will find a fragment of W&B documentation: the \u001b[1mTeam\u001b[0m dropdown menu, and select a role type \n",
       "from the \u001b[1mOrganizational Role\u001b[0m dropdown menu.                                                                        \n",
       "\n",
       "🌆 \u001b]8;id=355995;@site/static/images/app_ui/ezgif-3-b665ff2fa9.gif\u001b\\ezgif-3-b665ff2fa9.gif\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "\u001b[1;33m 5 \u001b[0mSelect the \u001b[1mAdd\u001b[0m button.                                                                                          \n",
       "\n",
       ":::info                                                                                                            \n",
       "\n",
       "\u001b[1;33m • \u001b[0mIf you have an Enterprise account, please contact your Account Executive to invite new members to your team. :::\n",
       "\n",
       "\n",
       "                                               \u001b[1;4mCreate a Team Profile\u001b[0m                                               \n",
       "\n",
       "You can customize your team's profile page to show an introduction and showcase reports and projects that are      \n",
       "visible to the public or team members. Present reports, projects, and external links.                              \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mHighlight your best research\u001b[0m to visitors by showcasing your best public reports                                 \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mShowcase the most active projects\u001b[0m to make it easier for teammates to find them                                  \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mFind collaborators\u001b[0m by adding external links to your company or research lab's website and any papers you've     \n",
       "\u001b[1;33m   \u001b[0mpublished                                                                                                       \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "                                                \u001b[1;4mRemove team members\u001b[0m                                                \n",
       "\n",
       "Team admins can open the team settings page and click the delete button next to the departing member's name. Any   \n",
       "runs that they logged to the team will remain after a user is removed.                                             \n",
       "\n",
       "\n",
       "                                            \u001b[1;4mTeam Roles and Permissions\u001b[0m                                             \n",
       "\n",
       "Select one a team role when you invite colleagues to join a team. There are four team role options:                \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mAdmin\u001b[0m: Team admins can add and remove other admins or team members. They have permissions to modify all projects\n",
       "\u001b[1;33m   \u001b[0mand full deletion permissions. This includes, but is not limited to, deleting runs, projects, artifacts, and    \n",
       "\u001b[1;33m   \u001b[0msweeps.                                                                                                         \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMember\u001b[0m: A regular member of the team. A team member is invited by email by the team admin. A team member cannot \n",
       "\u001b[1;33m   \u001b[0minvite other members. Team members can only delete runs and sweep runs created by that member. Suppose you have \n",
       "\u001b[1;33m   \u001b[0mtwo members A and B. Member B moves a Run from team B's project to a different project owned by Member A. Member\n",
       "\u001b[1;33m   \u001b[0mA can not delete the Run Member B moved to Member A's project. Only the member that creates the Run, or the team\n",
       "\u001b[1;33m   \u001b[0madmin, can delete the run.                                                                                      \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mService\u001b[0m: A service worker, an API key useful for using W&B with your run automation tools. If you use the API   \n",
       "\u001b[1;33m   \u001b[0mkey from a service account for your team, make sure to set the environment variable \u001b[1mWANDB_USERNAME\u001b[0m to attribute \n",
       "\u001b[1;33m   \u001b[0mruns to the correct user.                                                                                       \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mView-Only (Enterprise-only feature)\u001b[0m: View-Only members can view assets within the team such as runs, reports,   \n",
       "\u001b[1;33m   \u001b[0mand workspaces. They can Let's start!                                                                           \n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(generation_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate 3 possible questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the different roles available when inviting colleagues to join a team and what are their corresponding    \n",
       "permissions in W&amp;B?                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the different roles available when inviting colleagues to join a team and what are their corresponding    \n",
       "permissions in W&B?                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the different team roles in W&amp;B and what are their permissions?                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the different team roles in W&B and what are their permissions?                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">What are the different team roles and permissions in W&amp;B and what can each role do?                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "What are the different team roles and permissions in W&B and what can each role do?                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_print(system_prompt, generation_prompt, n=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As you can see, sometimes the generation contains an intro phrase like: \"Sure, here's a support question based on the documentation:\", we may want to put some instructions to avoid this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 5 prompt\n",
    "\n",
    "Complex directive that includes the following:\n",
    "- Description of high-level goal\n",
    "- A detailed bulleted list of sub-tasks\n",
    "- An explicit statement asking LLM to explain its own output\n",
    "- A guideline on how LLM output will be evaluated\n",
    "- Few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use GPT4 from here, as it gives better answers and abides to instructions better\n",
    "# I do not have access to GPT4, so I will use GPT3.5-turbo instead\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "# MODEL_NAME = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read system_template.txt file into an f-string\n",
    "with open(\"system_template.txt\", \"r\") as file:\n",
    "    system_prompt = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are a creative assistant with the goal to generate a synthetic dataset of Weights &amp; Biases (W&amp;B) user          \n",
       "questions. W&amp;B users are asking these questions to a bot, so they don't know the answer and their questions are    \n",
       "grounded in what they're trying to achieve. We are interested in questions that can be answered by W&amp;B             \n",
       "documentation. But the users don't have access to this documentation, so you need to imagine what they're trying to\n",
       "do and use according language.                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are a creative assistant with the goal to generate a synthetic dataset of Weights & Biases (W&B) user          \n",
       "questions. W&B users are asking these questions to a bot, so they don't know the answer and their questions are    \n",
       "grounded in what they're trying to achieve. We are interested in questions that can be answered by W&B             \n",
       "documentation. But the users don't have access to this documentation, so you need to imagine what they're trying to\n",
       "do and use according language.                                                                                     \n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read prompt_template.txt file into an f-string\n",
    "with open(\"prompt_template.txt\", \"r\") as file:\n",
    "    prompt_template = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "{QUESTIONS}                                                                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "In the next step, you will read a fragment of W&amp;B documentation. This will serve as inspiration for synthetic user \n",
       "question and the source of the answer. Here is the document fragment:                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "{CHUNK}                                                                                                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "You will now generate a user question and corresponding answer based on the above document. First, explain the user\n",
       "context and what problems they might be trying to solve. Second, generate user question. Third, provide the        \n",
       "accurate and concise answer in markdown format to the user question using the documentation. You'll be evaluated   \n",
       "on:                                                                                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>how realistic is that this question will come from a real user one day?                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>is this question about W&amp;B?                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>can the question be answered using the W&amp;B document fragment above?                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>how accurate is the answer? Remember that users have different styles and can be imprecise. You are very good at\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>impersonating them! Use the following format: CONTEXT: QUESTION: ANSWER: Let's start!                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "{QUESTIONS}                                                                                                        \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "In the next step, you will read a fragment of W&B documentation. This will serve as inspiration for synthetic user \n",
       "question and the source of the answer. Here is the document fragment:                                              \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "{CHUNK}                                                                                                            \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "You will now generate a user question and corresponding answer based on the above document. First, explain the user\n",
       "context and what problems they might be trying to solve. Second, generate user question. Third, provide the        \n",
       "accurate and concise answer in markdown format to the user question using the documentation. You'll be evaluated   \n",
       "on:                                                                                                                \n",
       "\n",
       "\u001b[1;33m • \u001b[0mhow realistic is that this question will come from a real user one day?                                         \n",
       "\u001b[1;33m • \u001b[0mis this question about W&B?                                                                                     \n",
       "\u001b[1;33m • \u001b[0mcan the question be answered using the W&B document fragment above?                                             \n",
       "\u001b[1;33m • \u001b[0mhow accurate is the answer? Remember that users have different styles and can be imprecise. You are very good at\n",
       "\u001b[1;33m   \u001b[0mimpersonating them! Use the following format: CONTEXT: QUESTION: ANSWER: Let's start!                           \n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_prompt(chunk, n_questions=3):\n",
    "    questions = '\\n'.join(random.sample(real_queries, n_questions))\n",
    "    user_prompt = prompt_template.format(QUESTIONS=questions, CHUNK=chunk)\n",
    "    return user_prompt\n",
    "\n",
    "user_prompt = generate_context_prompt(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "Is it possible to run parallel WANDB runs? I am trying to log an image but it's not appearing online. I am creating\n",
       "an Image object from RGBA data and then using wandb.log with commit=True. Logging of other images in the same      \n",
       "project works, just this one does not. What could the problem be? Weights &amp; Biases integration with Gradio works   \n",
       "within a Jupyter Notebook but not with the same code run as a Python script. Why is this the case?                 \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "In the next step, you will read a fragment of W&amp;B documentation. This will serve as inspiration for synthetic user \n",
       "question and the source of the answer. Here is the document fragment:                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "the <span style=\"font-weight: bold\">Team</span> dropdown menu, and select a role type from the <span style=\"font-weight: bold\">Organizational Role</span> dropdown menu.                         \n",
       "\n",
       "🌆 <a href=\"@site/static/images/app_ui/ezgif-3-b665ff2fa9.gif\" target=\"_blank\">ezgif-3-b665ff2fa9.gif</a>                                                                                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span>Select the <span style=\"font-weight: bold\">Add</span> button.                                                                                          \n",
       "\n",
       ":::info                                                                                                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>If you have an Enterprise account, please contact your Account Executive to invite new members to your team. :::\n",
       "\n",
       "\n",
       "                                               <span style=\"font-weight: bold; text-decoration: underline\">Create a Team Profile</span>                                               \n",
       "\n",
       "You can customize your team's profile page to show an introduction and showcase reports and projects that are      \n",
       "visible to the public or team members. Present reports, projects, and external links.                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Highlight your best research</span> to visitors by showcasing your best public reports                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Showcase the most active projects</span> to make it easier for teammates to find them                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Find collaborators</span> by adding external links to your company or research lab's website and any papers you've     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>published                                                                                                       \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "                                                <span style=\"font-weight: bold; text-decoration: underline\">Remove team members</span>                                                \n",
       "\n",
       "Team admins can open the team settings page and click the delete button next to the departing member's name. Any   \n",
       "runs that they logged to the team will remain after a user is removed.                                             \n",
       "\n",
       "\n",
       "                                            <span style=\"font-weight: bold; text-decoration: underline\">Team Roles and Permissions</span>                                             \n",
       "\n",
       "Select one a team role when you invite colleagues to join a team. There are four team role options:                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Admin</span>: Team admins can add and remove other admins or team members. They have permissions to modify all projects\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and full deletion permissions. This includes, but is not limited to, deleting runs, projects, artifacts, and    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>sweeps.                                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Member</span>: A regular member of the team. A team member is invited by email by the team admin. A team member cannot \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>invite other members. Team members can only delete runs and sweep runs created by that member. Suppose you have \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>two members A and B. Member B moves a Run from team B's project to a different project owned by Member A. Member\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>A can not delete the Run Member B moved to Member A's project. Only the member that creates the Run, or the team\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>admin, can delete the run.                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">Service</span>: A service worker, an API key useful for using W&amp;B with your run automation tools. If you use the API   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>key from a service account for your team, make sure to set the environment variable <span style=\"font-weight: bold\">WANDB_USERNAME</span> to attribute \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>runs to the correct user.                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">View-Only (Enterprise-only feature)</span>: View-Only members can view assets within the team such as runs, reports,   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>and workspaces. They can                                                                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "You will now generate a user question and corresponding answer based on the above document. First, explain the user\n",
       "context and what problems they might be trying to solve. Second, generate user question. Third, provide the        \n",
       "accurate and concise answer in markdown format to the user question using the documentation. You'll be evaluated   \n",
       "on:                                                                                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>how realistic is that this question will come from a real user one day?                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>is this question about W&amp;B?                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>can the question be answered using the W&amp;B document fragment above?                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>how accurate is the answer? Remember that users have different styles and can be imprecise. You are very good at\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>impersonating them! Use the following format: CONTEXT: QUESTION: ANSWER: Let's start!                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here are some examples of real user questions, you will be judged by how well you match this distribution.         \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "Is it possible to run parallel WANDB runs? I am trying to log an image but it's not appearing online. I am creating\n",
       "an Image object from RGBA data and then using wandb.log with commit=True. Logging of other images in the same      \n",
       "project works, just this one does not. What could the problem be? Weights & Biases integration with Gradio works   \n",
       "within a Jupyter Notebook but not with the same code run as a Python script. Why is this the case?                 \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "In the next step, you will read a fragment of W&B documentation. This will serve as inspiration for synthetic user \n",
       "question and the source of the answer. Here is the document fragment:                                              \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "the \u001b[1mTeam\u001b[0m dropdown menu, and select a role type from the \u001b[1mOrganizational Role\u001b[0m dropdown menu.                         \n",
       "\n",
       "🌆 \u001b]8;id=705467;@site/static/images/app_ui/ezgif-3-b665ff2fa9.gif\u001b\\ezgif-3-b665ff2fa9.gif\u001b]8;;\u001b\\                                                                                                                    \n",
       "\n",
       "\u001b[1;33m 5 \u001b[0mSelect the \u001b[1mAdd\u001b[0m button.                                                                                          \n",
       "\n",
       ":::info                                                                                                            \n",
       "\n",
       "\u001b[1;33m • \u001b[0mIf you have an Enterprise account, please contact your Account Executive to invite new members to your team. :::\n",
       "\n",
       "\n",
       "                                               \u001b[1;4mCreate a Team Profile\u001b[0m                                               \n",
       "\n",
       "You can customize your team's profile page to show an introduction and showcase reports and projects that are      \n",
       "visible to the public or team members. Present reports, projects, and external links.                              \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mHighlight your best research\u001b[0m to visitors by showcasing your best public reports                                 \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mShowcase the most active projects\u001b[0m to make it easier for teammates to find them                                  \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mFind collaborators\u001b[0m by adding external links to your company or research lab's website and any papers you've     \n",
       "\u001b[1;33m   \u001b[0mpublished                                                                                                       \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "                                                \u001b[1;4mRemove team members\u001b[0m                                                \n",
       "\n",
       "Team admins can open the team settings page and click the delete button next to the departing member's name. Any   \n",
       "runs that they logged to the team will remain after a user is removed.                                             \n",
       "\n",
       "\n",
       "                                            \u001b[1;4mTeam Roles and Permissions\u001b[0m                                             \n",
       "\n",
       "Select one a team role when you invite colleagues to join a team. There are four team role options:                \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1mAdmin\u001b[0m: Team admins can add and remove other admins or team members. They have permissions to modify all projects\n",
       "\u001b[1;33m   \u001b[0mand full deletion permissions. This includes, but is not limited to, deleting runs, projects, artifacts, and    \n",
       "\u001b[1;33m   \u001b[0msweeps.                                                                                                         \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mMember\u001b[0m: A regular member of the team. A team member is invited by email by the team admin. A team member cannot \n",
       "\u001b[1;33m   \u001b[0minvite other members. Team members can only delete runs and sweep runs created by that member. Suppose you have \n",
       "\u001b[1;33m   \u001b[0mtwo members A and B. Member B moves a Run from team B's project to a different project owned by Member A. Member\n",
       "\u001b[1;33m   \u001b[0mA can not delete the Run Member B moved to Member A's project. Only the member that creates the Run, or the team\n",
       "\u001b[1;33m   \u001b[0madmin, can delete the run.                                                                                      \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mService\u001b[0m: A service worker, an API key useful for using W&B with your run automation tools. If you use the API   \n",
       "\u001b[1;33m   \u001b[0mkey from a service account for your team, make sure to set the environment variable \u001b[1mWANDB_USERNAME\u001b[0m to attribute \n",
       "\u001b[1;33m   \u001b[0mruns to the correct user.                                                                                       \n",
       "\u001b[1;33m • \u001b[0m\u001b[1mView-Only (Enterprise-only feature)\u001b[0m: View-Only members can view assets within the team such as runs, reports,   \n",
       "\u001b[1;33m   \u001b[0mand workspaces. They can                                                                                        \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "You will now generate a user question and corresponding answer based on the above document. First, explain the user\n",
       "context and what problems they might be trying to solve. Second, generate user question. Third, provide the        \n",
       "accurate and concise answer in markdown format to the user question using the documentation. You'll be evaluated   \n",
       "on:                                                                                                                \n",
       "\n",
       "\u001b[1;33m • \u001b[0mhow realistic is that this question will come from a real user one day?                                         \n",
       "\u001b[1;33m • \u001b[0mis this question about W&B?                                                                                     \n",
       "\u001b[1;33m • \u001b[0mcan the question be answered using the W&B document fragment above?                                             \n",
       "\u001b[1;33m • \u001b[0mhow accurate is the answer? Remember that users have different styles and can be imprecise. You are very good at\n",
       "\u001b[1;33m   \u001b[0mimpersonating them! Use the following format: CONTEXT: QUESTION: ANSWER: Let's start!                           \n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(documents, n_questions=3, n_generations=5):\n",
    "    questions = []\n",
    "    for _, document in documents:\n",
    "        chunk = extract_random_chunk(document)\n",
    "        user_prompt = generate_context_prompt(chunk, n_questions)\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "        response = completion_with_backoff(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "            n = n_generations,\n",
    "            )\n",
    "        questions.extend([response.choices[i].message.content for i in range(n_generations)])\n",
    "    return questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A Note about the `system` role: For GPT4 based pipelines you probably want to move some part of the context prompt to the `system` context. As we are using `gpt3.5-turbo` here, you can put the instruction on the user prompt, you can read more about this on [OpenAI docs here](https://platform.openai.com/docs/guides/chat/instructing-chat-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse model generation and extract CONTEXT, QUESTION and ANSWER\n",
    "def parse_generation(generation):\n",
    "    lines = generation.split(\"\\n\")\n",
    "    context = []\n",
    "    question = []\n",
    "    answer = []\n",
    "    flag = None\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"CONTEXT:\" in line:\n",
    "            flag = \"context\"\n",
    "            line = line.replace(\"CONTEXT:\", \"\").strip()\n",
    "        elif \"QUESTION:\" in line:\n",
    "            flag = \"question\"\n",
    "            line = line.replace(\"QUESTION:\", \"\").strip()\n",
    "        elif \"ANSWER:\" in line:\n",
    "            flag = \"answer\"\n",
    "            line = line.replace(\"ANSWER:\", \"\").strip()\n",
    "\n",
    "        if flag == \"context\":\n",
    "            context.append(line)\n",
    "        elif flag == \"question\":\n",
    "            question.append(line)\n",
    "        elif flag == \"answer\":\n",
    "            answer.append(line)\n",
    "\n",
    "    context = \"\\n\".join(context)\n",
    "    question = \"\\n\".join(question)\n",
    "    answer = \"\\n\".join(answer)\n",
    "    return context, question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A user is part of a Weights & Biases team and wants to know which permissions they have to add models to the team registry. They are unsure if they have the necessary permissions, and if not, what they can do to obtain them.\\n',\n",
       " 'How can I add models to the registry of my team in Weights & Biases? Do I need any special permission?\\n',\n",
       " 'To add models to the registry of your team in Weights & Biases, you need to have the \"Team Member\" or \"Team Admin\" permission. If you don\\'t have this permission, you should contact an existing team admin to request it. Once you have the necessary permission, you can easily add models to the registry and share them with your team.')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generations = generate_questions([documents[0]], n_questions=3, n_generations=5)\n",
    "parse_generation(generations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.artifacts.local_artifact.Artifact at 0x7f51a5a3bfd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_generations = []\n",
    "generations = generate_questions(documents, n_questions=3, n_generations=5)\n",
    "for generation in generations:\n",
    "    context, question, answer = parse_generation(generation)\n",
    "    parsed_generations.append({\"context\": context, \"question\": question, \"answer\": answer})\n",
    "\n",
    "# let's convert parsed_generations to a pandas dataframe and save it locally\n",
    "df = pd.DataFrame(parsed_generations)\n",
    "df.to_csv('generated_examples.csv', index=False)\n",
    "\n",
    "# log df as a table to W&B for interactive exploration\n",
    "wandb.log({\"generated_examples\": wandb.Table(dataframe=df)})\n",
    "\n",
    "# log csv file as an artifact to W&B for later use\n",
    "artifact = wandb.Artifact(\"generated_examples\", type=\"dataset\")\n",
    "artifact.add_file(\"generated_examples.csv\")\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>▁▂▁▄▅▆█▅▆▆▄▅▆▆▆</td></tr><tr><td>usage/elapsed_time</td><td>▁▃▁▅▆▆█▆▆▆▆▅▆▆▇</td></tr><tr><td>usage/prompt_tokens</td><td>▁▂▅▇▇▇█▇▇▇▇▆▇▇▇</td></tr><tr><td>usage/total_tokens</td><td>▁▂▂▅▆▆█▆▆▇▅▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>1144</td></tr><tr><td>usage/elapsed_time</td><td>11.49716</td></tr><tr><td>usage/prompt_tokens</td><td>915</td></tr><tr><td>usage/total_tokens</td><td>2059</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devoted-energy-4</strong> at: <a href='https://wandb.ai/cmagganas/llmapps/runs/vfjiv4yp' target=\"_blank\">https://wandb.ai/cmagganas/llmapps/runs/vfjiv4yp</a><br/>Synced 6 W&B file(s), 16 media file(s), 17 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230626_211011-vfjiv4yp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
